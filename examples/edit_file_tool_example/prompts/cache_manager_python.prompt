# Module: edit_file_tool/cache_manager.py

## Role and Responsibilities
This module is responsible for implementing the "Smart Cache Management" logic for the Edit File Tool. Its primary purpose is to intelligently decide when to use Anthropic's native prompt caching to optimize API costs, especially when performing multiple edits on the same file.

The module will encapsulate all the rules for cache auto-detection based on file size and complexity, as described in the project documentation. It will provide a clear interface for other parts of the application (like the Anthropic service layer) to query whether caching should be enabled for a given file and user preference.

Key responsibilities include:
- Implementing a `CacheManager` class to contain the caching logic.
- Supporting three user-configurable caching modes: `auto`, `always`, and `never`.
- In `auto` mode, analyzing file characteristics (size, line count, content density) to make an informed decision.
- Providing a single, easy-to-use method that returns a boolean indicating whether to use the cache.
- Tracking cache-related metrics (e.g., estimated savings, cache reads/writes) for reporting purposes.
- Supporting TTL concepts and pass-through of cache-related options to the API layer when applicable.

References:
- Anthropic Prompt Caching documentation: <anthropic_prompt_caching_docs><web>https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching</web></anthropic_prompt_caching_docs>

## Requirements
1.  **Functional Requirements:**
    *   Implement a `CacheManager` class.
    *   The class must provide a public method `should_use_cache` that takes the file path, file content, and a user-specified cache mode (`"auto"`, `True` for "always", `False` for "never") as input.
    *   The `should_use_cache` method must return a boolean value.
    *   The method must correctly interpret the user-specified cache mode:
        *   If mode is `True` or `"always"`, it must always return `True`.
        *   If mode is `False` or `"never"`, it must always return `False`.
        *   If mode is `"auto"`, it must execute the smart auto-detection logic.
    *   The **auto-detection logic** must adhere to the following rules from the project documentation:
        *   Calculate file size from the provided file content.
        *   **Small files (< 1KB):** Caching must be disabled (return `False`).
        *   **Large files (> 4KB):** Caching must be enabled (return `True`).
        *   **Medium files (1KB - 4KB):** The decision must be based on a complexity analysis.
            *   The analysis must consider: total line count, number of non-empty lines, and content density (ratio of non-whitespace characters to total characters).
            *   A reasonable heuristic must be implemented to determine if a medium-sized file is "complex" enough to benefit from caching.
    *   Optionally expose helper(s) to return decision metadata (e.g., reason string and metrics) without changing the primary `bool` return contract for `should_use_cache`.

2.  **Performance Requirements:**
    *   The file analysis must be highly efficient and add negligible overhead to the overall process.
    *   File size calculation should be based on the in-memory content string to avoid redundant I/O operations.

3.  **Security Requirements:**
    *   The module should not perform any file I/O itself; it should operate on the file content passed to it. This limits its security exposure.

4.  **Error Handling Requirements:**
    *   The implementation must be robust and handle edge cases gracefully, such as empty files or content with unusual formatting.
    *   It should not raise exceptions for valid inputs.

5.  **Documentation Requirements:**
    *   All classes and methods must have comprehensive docstrings following the Google Python Style Guide.
    *   Full type hints are required for all function signatures and variables.
    *   The heuristic for complexity analysis in `auto` mode must be clearly documented in the code.
    *   Where relevant, cite Anthropic prompt caching best practices using the reference above.

## Dependencies
Standard Library:
- `typing`: For type hints (`Union`, `Optional`, `Dict`).

Third-party:
- None

Internal (per `pdd/architecture.json`):
- `edit_file_tool/utils.py`: Logging, error formatting, and cost formatting helpers.
- `edit_file_tool/file_io.py`: File metrics helpers when needed (line counts, density calculations) without performing I/O in this module.
- `edit_file_tool/claude_api.py`: For integration points to pass cache decisions and options (e.g., TTL) into API requests.

## Implementation Instructions
1.  **File and Class Structure:**
    *   Create the file `edit_file_tool/cache_manager.py`.
    *   Define module-level constants for the file size thresholds:
        *   `SMALL_FILE_THRESHOLD_BYTES = 1 * 1024`
        *   `LARGE_FILE_THRESHOLD_BYTES = 4 * 1024`
    *   Implement a `CacheManager` class.

2.  **`CacheManager` Class:**
    *   The `__init__` method can be a simple `pass` as no initial state is required.
    *   Implement the primary public method: `should_use_cache(self, file_content: str, use_cache_flag: Union[str, bool]) -> bool`.
    *   This method should first check and handle the explicit `use_cache_flag` values (`True`, `False`, `"always"`, `"never"`).
    *   If the flag is `"auto"`, proceed to the auto-detection logic.

3.  **Auto-Detection Logic:**
    *   Calculate the file size in bytes using `len(file_content.encode('utf-8'))`.
    *   Implement the size-based rules:
        *   If `file_size < SMALL_FILE_THRESHOLD_BYTES`, return `False`.
        *   If `file_size > LARGE_FILE_THRESHOLD_BYTES`, return `True`.
    *   For files between the thresholds, call a private helper method, e.g., `_is_complex_enough(self, file_content: str) -> bool`.

% Example of computing file metrics and content density heuristics: <file_metrics_example>
```python
# examples/file_io_example.py

# This is an example of how helpers in `file_io.py` might be used
# to compute metrics from file content string. The CacheManager would
# use these helpers.

def calculate_file_metrics(file_content: str) -> dict:
    """
    Calculates various metrics from a file's content string.

    Args:
        file_content: The string content of the file.

    Returns:
        A dictionary containing file metrics.
    """
    if not file_content:
        return {
            "total_chars": 0,
            "whitespace_chars": 0,
            "non_whitespace_chars": 0,
            "line_count": 0,
            "non_empty_line_count": 0,
            "content_density": 0.0,
        }

    lines = file_content.splitlines()
    total_chars = len(file_content)
    non_whitespace_chars = len("".join(file_content.split()))
    whitespace_chars = total_chars - non_whitespace_chars

    # Calculate content density, handle division by zero
    content_density = (
        float(non_whitespace_chars) / total_chars if total_chars > 0 else 0.0
    )

    return {
        "total_chars": total_chars,
        "whitespace_chars": whitespace_chars,
        "non_whitespace_chars": non_whitespace_chars,
        "line_count": len(lines),
        "non_empty_line_count": sum(1 for line in lines if line.strip()),
        "content_density": content_density,
    }

# --- Example Usage ---
# In cache_manager.py, you might use it like this:
#
# from edit_file_tool.file_io import calculate_file_metrics
#
# def _is_complex_enough(self, file_content: str) -> bool:
#     metrics = calculate_file_metrics(file_content)
#     is_complex = (
#         metrics["line_count"] > 50 and
#         metrics["non_empty_line_count"] > 30 and
#         metrics["content_density"] > 0.5
#     )
#     return is_complex
```
</file_metrics_example>

4.  **Complexity Analysis Helper (`_is_complex_enough`):**
    *   This private method will contain the heuristic for medium-sized files.
    *   Calculate the following metrics from the `file_content`:
        *   `line_count`: Total number of lines.
        *   `non_empty_line_count`: Number of lines that are not just whitespace.
        *   `content_density`: Ratio of non-whitespace characters to the total number of characters. Handle the case of division by zero for empty content.
    *   Implement a heuristic combining these metrics. For example:
        ```python
        # A potential heuristic, you can refine this.
        is_complex = (
            line_count > 50 and
            non_empty_line_count > 30 and
            content_density > 0.5
        )
        return is_complex
        ```
    *   Document the chosen heuristic clearly in the method's docstring.

% Example of summarizing and formatting metrics for reporting: <metrics_formatting_example>
```python
# examples/utils_example.py

# This is an example of how helpers in `utils.py` might be used
# to format decision metadata for logging or reporting.

def format_cache_decision_reason(decision: bool, reason: str, metrics: dict) -> str:
    """
    Formats a human-readable string explaining a cache decision.

    Args:
        decision: The boolean cache decision (True or False).
        reason: A short string code for the reason (e.g., 'AUTO_LARGE_FILE').
        metrics: A dictionary of metrics used to make the decision.

    Returns:
        A formatted string for logging.
    """
    decision_str = "Enabled" if decision else "Disabled"
    formatted_metrics = ", ".join(f"{k}={v:.2f}" if isinstance(v, float) else f"{k}={v}" for k, v in metrics.items())
    return f"Cache {decision_str}. Reason: {reason}. Metrics: [{formatted_metrics}]"

# --- Example Usage ---
# In a higher-level function that calls CacheManager, you might do this:
#
# from edit_file_tool.utils import format_cache_decision_reason
# from edit_file_tool.cache_manager import CacheManager
#
# manager = CacheManager()
# # get_decision_metadata would be an optional method on CacheManager
# decision, metadata = manager.get_decision_metadata(file_content, "auto")
#
# log_message = format_cache_decision_reason(
#     decision,
#     metadata["reason"],
#     metadata["metrics"]
# )
# print(log_message)
# # Expected output:
# # Cache Enabled. Reason: AUTO_COMPLEX_FILE. Metrics: [size_kb=2.5, line_count=120, content_density=0.75]
```
</metrics_formatting_example>

5.  **Code Style and Quality:**
    *   Adhere to PEP 8 standards.
    *   Use f-strings for any string formatting.
    *   Ensure all code is clean, readable, and well-commented where necessary.

6.  **Integration with API Layer:**
    *   Ensure the decision outcome can be consumed by the API layer. For example, when `should_use_cache(...)` returns `True`, the caller should set `use_cache=True` for the next API call so that cache-control headers are injected appropriately.

% Example of passing cache decisions into the API call path: <api_cache_usage_example>
```python
# examples/claude_api_example.py

# This is an example of how the boolean decision from CacheManager
# would be passed down to the Anthropic API call layer.

class ClaudeAPI:
    def __init__(self, client):
        self.client = client # Assume an initialized Anthropic client

    def execute_edit(self, prompt: str, use_cache: bool):
        """
        Executes an edit command by calling the Claude API.

        The `use_cache` parameter directly controls whether caching headers
        are sent with the API request.

        Args:
            prompt: The full prompt for the edit.
            use_cache: The decision from CacheManager.
        """
        print(f"--- Claude API Call ---")
        print(f"Received use_cache flag: {use_cache}")

        # The Anthropic Python SDK might handle this via a parameter.
        # For example: `self.client.messages.create(..., use_cache=use_cache)`
        # This parameter would then add the required
        # `anthropic-beta: prompt-caching-2024-07-31` header.
        if use_cache:
            print("Integration: Setting API parameters to USE cache.")
            # Fictional SDK call
            # response = self.client.messages.create(..., extra_headers={"anthropic-beta": "prompt-caching-2024-07-31"})
        else:
            print("Integration: Setting API parameters to NOT use cache.")
            # Fictional SDK call
            # response = self.client.messages.create(...)
        print("--- End API Call ---")
        return "Simulated API response"


# --- Example Usage in the main application flow ---
#
# from edit_file_tool.cache_manager import CacheManager
# from edit_file_tool.claude_api import ClaudeAPI
#
# # Assume file_content and prompt are defined
# file_content = "..."
# edit_prompt = "..."
#
# # 1. Get decision from CacheManager
# cache_manager = CacheManager()
# should_cache = cache_manager.should_use_cache(file_content, use_cache_flag="auto")
#
# # 2. Pass decision to the API layer
# api_service = ClaudeAPI(client=...)
# result = api_service.execute_edit(prompt=edit_prompt, use_cache=should_cache)
```
</api_cache_usage_example>

## Key Functions and Classes
```python
class CacheManager:
    """
    Manages the logic for deciding when to use Anthropic's native prompt caching.
    """

    def __init__(self):
        """Initializes the CacheManager."""
        ...

    def should_use_cache(self, file_content: str, use_cache_flag: Union[str, bool]) -> bool:
        """
        Determines if caching should be used based on file characteristics and user preference.

        Args:
            file_content: The content of the file to be analyzed.
            use_cache_flag: The user-specified caching preference ('auto', True, False, 'always', 'never').

        Returns:
            True if caching should be enabled, False otherwise.
        """
        ...

    def _is_complex_enough(self, file_content: str) -> bool:
        """
        Analyzes a medium-sized file's content to determine if it's complex enough for caching.

        Args:
            file_content: The content of the file.

        Returns:
            True if the file is deemed complex, False otherwise.
        """
        ...
```

## Deliverables
1.  The complete and final implementation of the `edit_file_tool/cache_manager.py` module.
2.  A corresponding unit test file `tests/test_cache_manager.py`.
3.  The unit tests must provide comprehensive coverage for the `CacheManager` class, including:
    *   Tests for each explicit cache mode (`always`, `never`, `True`, `False`).
    *   Tests for the `auto` mode on small, medium, and large files.
    *   Tests for the complexity heuristic on medium files, covering both cases where it returns `True` and `False`.
    *   Edge case tests, such as an empty file.
4.  Full type hinting for all functions, methods, and variables.
5.  Comprehensive docstrings in Google style for the module, class, and all methods.
6.  Robust implementation that handles all specified requirements and edge cases gracefully.
7.  Include examples in the prompt specification that mirror usage patterns from `examples/file_io_example.py`, `examples/utils_example.py`, and `examples/claude_api_example.py` to guide implementation and integration.